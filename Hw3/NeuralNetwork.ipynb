{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Activation,Dropout\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1811 samples, validate on 453 samples\n",
      "Epoch 1/50\n",
      "1811/1811 [==============================] - 0s 153us/step - loss: 0.6928 - acc: 0.5395 - val_loss: 0.6919 - val_acc: 0.5497\n",
      "Epoch 2/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6915 - acc: 0.5456 - val_loss: 0.6913 - val_acc: 0.5497\n",
      "Epoch 3/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6904 - acc: 0.5456 - val_loss: 0.6909 - val_acc: 0.5497\n",
      "Epoch 4/50\n",
      "1811/1811 [==============================] - 0s 26us/step - loss: 0.6895 - acc: 0.5456 - val_loss: 0.6903 - val_acc: 0.5497\n",
      "Epoch 5/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6889 - acc: 0.5456 - val_loss: 0.6904 - val_acc: 0.5497\n",
      "Epoch 6/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6886 - acc: 0.5456 - val_loss: 0.6908 - val_acc: 0.5497\n",
      "Epoch 7/50\n",
      "1811/1811 [==============================] - 0s 27us/step - loss: 0.6885 - acc: 0.5456 - val_loss: 0.6912 - val_acc: 0.5497\n",
      "Epoch 8/50\n",
      "1811/1811 [==============================] - 0s 28us/step - loss: 0.6882 - acc: 0.5456 - val_loss: 0.6922 - val_acc: 0.5143\n",
      "Epoch 9/50\n",
      "1811/1811 [==============================] - 0s 28us/step - loss: 0.6880 - acc: 0.5456 - val_loss: 0.6932 - val_acc: 0.5166\n",
      "Epoch 10/50\n",
      "1811/1811 [==============================] - 0s 26us/step - loss: 0.6879 - acc: 0.5456 - val_loss: 0.6932 - val_acc: 0.5188\n",
      "Epoch 11/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6880 - acc: 0.5445 - val_loss: 0.6940 - val_acc: 0.4857\n",
      "Epoch 12/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6878 - acc: 0.5461 - val_loss: 0.6957 - val_acc: 0.4724\n",
      "Epoch 13/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6877 - acc: 0.5450 - val_loss: 0.6968 - val_acc: 0.4525\n",
      "Epoch 14/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6877 - acc: 0.5478 - val_loss: 0.6969 - val_acc: 0.4614\n",
      "Epoch 15/50\n",
      "1811/1811 [==============================] - 0s 25us/step - loss: 0.6875 - acc: 0.5555 - val_loss: 0.6987 - val_acc: 0.4481\n",
      "Epoch 16/50\n",
      "1811/1811 [==============================] - 0s 25us/step - loss: 0.6875 - acc: 0.5555 - val_loss: 0.6998 - val_acc: 0.4503\n",
      "Epoch 17/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6874 - acc: 0.5560 - val_loss: 0.6992 - val_acc: 0.4503\n",
      "Epoch 18/50\n",
      "1811/1811 [==============================] - 0s 27us/step - loss: 0.6875 - acc: 0.5605 - val_loss: 0.7011 - val_acc: 0.4570\n",
      "Epoch 19/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6874 - acc: 0.5494 - val_loss: 0.7020 - val_acc: 0.4547\n",
      "Epoch 20/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6873 - acc: 0.5538 - val_loss: 0.7009 - val_acc: 0.4459\n",
      "Epoch 21/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6873 - acc: 0.5533 - val_loss: 0.7014 - val_acc: 0.4415\n",
      "Epoch 22/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6871 - acc: 0.5572 - val_loss: 0.7046 - val_acc: 0.4547\n",
      "Epoch 23/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6871 - acc: 0.5577 - val_loss: 0.7037 - val_acc: 0.4570\n",
      "Epoch 24/50\n",
      "1811/1811 [==============================] - 0s 26us/step - loss: 0.6870 - acc: 0.5538 - val_loss: 0.7067 - val_acc: 0.4547\n",
      "Epoch 25/50\n",
      "1811/1811 [==============================] - 0s 26us/step - loss: 0.6871 - acc: 0.5566 - val_loss: 0.7072 - val_acc: 0.4592\n",
      "Epoch 26/50\n",
      "1811/1811 [==============================] - 0s 27us/step - loss: 0.6870 - acc: 0.5544 - val_loss: 0.7090 - val_acc: 0.4570\n",
      "Epoch 27/50\n",
      "1811/1811 [==============================] - 0s 28us/step - loss: 0.6870 - acc: 0.5549 - val_loss: 0.7064 - val_acc: 0.4614\n",
      "Epoch 28/50\n",
      "1811/1811 [==============================] - 0s 27us/step - loss: 0.6870 - acc: 0.5555 - val_loss: 0.7090 - val_acc: 0.4570\n",
      "Epoch 29/50\n",
      "1811/1811 [==============================] - 0s 25us/step - loss: 0.6868 - acc: 0.5538 - val_loss: 0.7095 - val_acc: 0.4547\n",
      "Epoch 30/50\n",
      "1811/1811 [==============================] - 0s 25us/step - loss: 0.6868 - acc: 0.5560 - val_loss: 0.7102 - val_acc: 0.4547\n",
      "Epoch 31/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6868 - acc: 0.5516 - val_loss: 0.7090 - val_acc: 0.4592\n",
      "Epoch 32/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6867 - acc: 0.5527 - val_loss: 0.7108 - val_acc: 0.4547\n",
      "Epoch 33/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6867 - acc: 0.5560 - val_loss: 0.7111 - val_acc: 0.4592\n",
      "Epoch 34/50\n",
      "1811/1811 [==============================] - 0s 25us/step - loss: 0.6866 - acc: 0.5544 - val_loss: 0.7107 - val_acc: 0.4614\n",
      "Epoch 35/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6867 - acc: 0.5516 - val_loss: 0.7104 - val_acc: 0.4592\n",
      "Epoch 36/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6866 - acc: 0.5560 - val_loss: 0.7124 - val_acc: 0.4570\n",
      "Epoch 37/50\n",
      "1811/1811 [==============================] - 0s 27us/step - loss: 0.6866 - acc: 0.5533 - val_loss: 0.7142 - val_acc: 0.4525\n",
      "Epoch 38/50\n",
      "1811/1811 [==============================] - 0s 27us/step - loss: 0.6865 - acc: 0.5560 - val_loss: 0.7159 - val_acc: 0.4503\n",
      "Epoch 39/50\n",
      "1811/1811 [==============================] - 0s 27us/step - loss: 0.6865 - acc: 0.5533 - val_loss: 0.7146 - val_acc: 0.4570\n",
      "Epoch 40/50\n",
      "1811/1811 [==============================] - 0s 25us/step - loss: 0.6865 - acc: 0.5583 - val_loss: 0.7154 - val_acc: 0.4547\n",
      "Epoch 41/50\n",
      "1811/1811 [==============================] - 0s 26us/step - loss: 0.6864 - acc: 0.5538 - val_loss: 0.7162 - val_acc: 0.4547\n",
      "Epoch 42/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6864 - acc: 0.5516 - val_loss: 0.7168 - val_acc: 0.4570\n",
      "Epoch 43/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6864 - acc: 0.5544 - val_loss: 0.7161 - val_acc: 0.4614\n",
      "Epoch 44/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6864 - acc: 0.5577 - val_loss: 0.7180 - val_acc: 0.4481\n",
      "Epoch 45/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6863 - acc: 0.5522 - val_loss: 0.7166 - val_acc: 0.4614\n",
      "Epoch 46/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6863 - acc: 0.5544 - val_loss: 0.7179 - val_acc: 0.4547\n",
      "Epoch 47/50\n",
      "1811/1811 [==============================] - 0s 24us/step - loss: 0.6862 - acc: 0.5544 - val_loss: 0.7209 - val_acc: 0.4481\n",
      "Epoch 48/50\n",
      "1811/1811 [==============================] - 0s 23us/step - loss: 0.6862 - acc: 0.5538 - val_loss: 0.7243 - val_acc: 0.4525\n",
      "Epoch 49/50\n",
      "1811/1811 [==============================] - 0s 25us/step - loss: 0.6863 - acc: 0.5538 - val_loss: 0.7197 - val_acc: 0.4547\n",
      "Epoch 50/50\n",
      "1811/1811 [==============================] - 0s 22us/step - loss: 0.6861 - acc: 0.5527 - val_loss: 0.7229 - val_acc: 0.4481\n",
      "2264/2264 [==============================] - 0s 9us/step\n",
      "252/252 [==============================] - 0s 12us/step\n",
      "\n",
      "\n",
      "Accuracy of test:\n",
      "0.5198412684221116\n"
     ]
    }
   ],
   "source": [
    "# 讀取train.csv和test.csv\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train=train.drop([\"Unnamed: 0\"], axis=1)\n",
    "test=test.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# 將train和test的資料分為features和target\n",
    "# train_x為features,train_y為target\n",
    "# test_x為features,test_y為target\n",
    "column_list=list(train.columns.values)\n",
    "column_list.remove(\"target\")\n",
    "train_x=train[column_list]\n",
    "train_y=train[[\"target\"]]\n",
    "test_x=test[column_list]\n",
    "test_y=test[[\"target\"]]\n",
    "train_x = train_x.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "test_x = test_x.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "train_x=train_x.fillna(0)\n",
    "test_x=test_x.fillna(0)\n",
    "\n",
    "# create the model\n",
    "model=Sequential()\n",
    "\n",
    "# add layers\n",
    "model.add(Dense(units=10,input_dim=train_x.shape[1],kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(units=1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "\n",
    "# show the summary\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history=model.fit(train_x,train_y,epochs=50,batch_size=32,validation_split=0.2,verbose=1)\n",
    "\n",
    "# evaluate\n",
    "train_acc=model.evaluate(train_x,train_y,batch_size=32)[1]\n",
    "test_acc=model.evaluate(test_x,test_y,batch_size=32)[1]\n",
    "\n",
    "# print result\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Accuracy of test:\")\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, input_shape=(1, 9), return_sequences=True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_45 (LSTM)               (None, 1, 10)             800       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,651\n",
      "Trainable params: 1,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1811 samples, validate on 453 samples\n",
      "Epoch 1/50\n",
      "1811/1811 [==============================] - 5s 3ms/step - loss: 0.6924 - acc: 0.5450 - val_loss: 0.6915 - val_acc: 0.5497\n",
      "Epoch 2/50\n",
      "1811/1811 [==============================] - 0s 177us/step - loss: 0.6910 - acc: 0.5456 - val_loss: 0.6904 - val_acc: 0.5497\n",
      "Epoch 3/50\n",
      "1811/1811 [==============================] - 0s 176us/step - loss: 0.6899 - acc: 0.5456 - val_loss: 0.6898 - val_acc: 0.5497\n",
      "Epoch 4/50\n",
      "1811/1811 [==============================] - 0s 175us/step - loss: 0.6892 - acc: 0.5456 - val_loss: 0.6895 - val_acc: 0.5497\n",
      "Epoch 5/50\n",
      "1811/1811 [==============================] - 0s 196us/step - loss: 0.6888 - acc: 0.5456 - val_loss: 0.6894 - val_acc: 0.5497\n",
      "Epoch 6/50\n",
      "1811/1811 [==============================] - 0s 193us/step - loss: 0.6883 - acc: 0.5456 - val_loss: 0.6895 - val_acc: 0.5497\n",
      "Epoch 7/50\n",
      "1811/1811 [==============================] - 0s 198us/step - loss: 0.6882 - acc: 0.5456 - val_loss: 0.6898 - val_acc: 0.5497\n",
      "Epoch 8/50\n",
      "1811/1811 [==============================] - 0s 181us/step - loss: 0.6888 - acc: 0.5456 - val_loss: 0.6899 - val_acc: 0.5497\n",
      "Epoch 9/50\n",
      "1811/1811 [==============================] - 0s 195us/step - loss: 0.6884 - acc: 0.5456 - val_loss: 0.6901 - val_acc: 0.5497\n",
      "Epoch 10/50\n",
      "1811/1811 [==============================] - 0s 181us/step - loss: 0.6887 - acc: 0.5456 - val_loss: 0.6901 - val_acc: 0.5497\n",
      "Epoch 11/50\n",
      "1811/1811 [==============================] - 0s 177us/step - loss: 0.6889 - acc: 0.5456 - val_loss: 0.6900 - val_acc: 0.5497\n",
      "Epoch 12/50\n",
      "1811/1811 [==============================] - 0s 178us/step - loss: 0.6885 - acc: 0.5456 - val_loss: 0.6900 - val_acc: 0.5497\n",
      "Epoch 13/50\n",
      "1811/1811 [==============================] - 0s 179us/step - loss: 0.6884 - acc: 0.5456 - val_loss: 0.6900 - val_acc: 0.5497\n",
      "Epoch 14/50\n",
      "1811/1811 [==============================] - 0s 199us/step - loss: 0.6883 - acc: 0.5456 - val_loss: 0.6902 - val_acc: 0.5497\n",
      "Epoch 15/50\n",
      "1811/1811 [==============================] - 0s 193us/step - loss: 0.6882 - acc: 0.5456 - val_loss: 0.6904 - val_acc: 0.5497\n",
      "Epoch 16/50\n",
      "1811/1811 [==============================] - 0s 188us/step - loss: 0.6881 - acc: 0.5456 - val_loss: 0.6905 - val_acc: 0.5497\n",
      "Epoch 17/50\n",
      "1811/1811 [==============================] - 0s 183us/step - loss: 0.6888 - acc: 0.5456 - val_loss: 0.6906 - val_acc: 0.5497\n",
      "Epoch 18/50\n",
      "1811/1811 [==============================] - 0s 184us/step - loss: 0.6883 - acc: 0.5456 - val_loss: 0.6909 - val_acc: 0.5497\n",
      "Epoch 19/50\n",
      "1811/1811 [==============================] - 0s 200us/step - loss: 0.6879 - acc: 0.5456 - val_loss: 0.6909 - val_acc: 0.5497\n",
      "Epoch 20/50\n",
      "1811/1811 [==============================] - 0s 184us/step - loss: 0.6882 - acc: 0.5456 - val_loss: 0.6907 - val_acc: 0.5497\n",
      "Epoch 21/50\n",
      "1811/1811 [==============================] - 0s 201us/step - loss: 0.6881 - acc: 0.5456 - val_loss: 0.6912 - val_acc: 0.5475\n",
      "Epoch 22/50\n",
      "1811/1811 [==============================] - 0s 195us/step - loss: 0.6881 - acc: 0.5456 - val_loss: 0.6914 - val_acc: 0.5430\n",
      "Epoch 23/50\n",
      "1811/1811 [==============================] - 0s 192us/step - loss: 0.6889 - acc: 0.5456 - val_loss: 0.6917 - val_acc: 0.5342\n",
      "Epoch 24/50\n",
      "1811/1811 [==============================] - 0s 196us/step - loss: 0.6880 - acc: 0.5456 - val_loss: 0.6916 - val_acc: 0.5430\n",
      "Epoch 25/50\n",
      "1811/1811 [==============================] - 0s 183us/step - loss: 0.6880 - acc: 0.5456 - val_loss: 0.6916 - val_acc: 0.5386\n",
      "Epoch 26/50\n",
      "1811/1811 [==============================] - 0s 202us/step - loss: 0.6882 - acc: 0.5461 - val_loss: 0.6918 - val_acc: 0.5276\n",
      "Epoch 27/50\n",
      "1811/1811 [==============================] - 0s 189us/step - loss: 0.6883 - acc: 0.5461 - val_loss: 0.6920 - val_acc: 0.5121\n",
      "Epoch 28/50\n",
      "1811/1811 [==============================] - 0s 197us/step - loss: 0.6884 - acc: 0.5456 - val_loss: 0.6922 - val_acc: 0.5099\n",
      "Epoch 29/50\n",
      "1811/1811 [==============================] - 0s 179us/step - loss: 0.6883 - acc: 0.5461 - val_loss: 0.6920 - val_acc: 0.5143\n",
      "Epoch 30/50\n",
      "1811/1811 [==============================] - 0s 200us/step - loss: 0.6880 - acc: 0.5461 - val_loss: 0.6925 - val_acc: 0.5143\n",
      "Epoch 31/50\n",
      "1811/1811 [==============================] - 0s 187us/step - loss: 0.6879 - acc: 0.5445 - val_loss: 0.6927 - val_acc: 0.5055\n",
      "Epoch 32/50\n",
      "1811/1811 [==============================] - 0s 185us/step - loss: 0.6871 - acc: 0.5494 - val_loss: 0.6929 - val_acc: 0.5143\n",
      "Epoch 33/50\n",
      "1811/1811 [==============================] - 0s 180us/step - loss: 0.6880 - acc: 0.5489 - val_loss: 0.6935 - val_acc: 0.5077\n",
      "Epoch 34/50\n",
      "1811/1811 [==============================] - 0s 185us/step - loss: 0.6873 - acc: 0.5467 - val_loss: 0.6937 - val_acc: 0.4967\n",
      "Epoch 35/50\n",
      "1811/1811 [==============================] - 0s 199us/step - loss: 0.6871 - acc: 0.5483 - val_loss: 0.6944 - val_acc: 0.4945\n",
      "Epoch 36/50\n",
      "1811/1811 [==============================] - 0s 179us/step - loss: 0.6873 - acc: 0.5500 - val_loss: 0.6950 - val_acc: 0.4790\n",
      "Epoch 37/50\n",
      "1811/1811 [==============================] - 0s 182us/step - loss: 0.6872 - acc: 0.5461 - val_loss: 0.6957 - val_acc: 0.4768\n",
      "Epoch 38/50\n",
      "1811/1811 [==============================] - 0s 179us/step - loss: 0.6875 - acc: 0.5483 - val_loss: 0.6957 - val_acc: 0.4812\n",
      "Epoch 39/50\n",
      "1811/1811 [==============================] - 0s 179us/step - loss: 0.6873 - acc: 0.5555 - val_loss: 0.6959 - val_acc: 0.4746\n",
      "Epoch 40/50\n",
      "1811/1811 [==============================] - 0s 192us/step - loss: 0.6885 - acc: 0.5433 - val_loss: 0.6962 - val_acc: 0.4812\n",
      "Epoch 41/50\n",
      "1811/1811 [==============================] - 0s 187us/step - loss: 0.6874 - acc: 0.5461 - val_loss: 0.6966 - val_acc: 0.4724\n",
      "Epoch 42/50\n",
      "1811/1811 [==============================] - 0s 187us/step - loss: 0.6877 - acc: 0.5500 - val_loss: 0.6968 - val_acc: 0.4746\n",
      "Epoch 43/50\n",
      "1811/1811 [==============================] - 0s 179us/step - loss: 0.6863 - acc: 0.5467 - val_loss: 0.6974 - val_acc: 0.4658\n",
      "Epoch 44/50\n",
      "1811/1811 [==============================] - 0s 178us/step - loss: 0.6874 - acc: 0.5445 - val_loss: 0.6971 - val_acc: 0.4724\n",
      "Epoch 45/50\n",
      "1811/1811 [==============================] - 0s 176us/step - loss: 0.6874 - acc: 0.5439 - val_loss: 0.6970 - val_acc: 0.4768\n",
      "Epoch 46/50\n",
      "1811/1811 [==============================] - 0s 181us/step - loss: 0.6875 - acc: 0.5483 - val_loss: 0.6970 - val_acc: 0.4768\n",
      "Epoch 47/50\n",
      "1811/1811 [==============================] - 0s 188us/step - loss: 0.6874 - acc: 0.5527 - val_loss: 0.6972 - val_acc: 0.4724\n",
      "Epoch 48/50\n",
      "1811/1811 [==============================] - 0s 191us/step - loss: 0.6866 - acc: 0.5483 - val_loss: 0.6984 - val_acc: 0.4680\n",
      "Epoch 49/50\n",
      "1811/1811 [==============================] - 0s 181us/step - loss: 0.6875 - acc: 0.5505 - val_loss: 0.6987 - val_acc: 0.4658\n",
      "Epoch 50/50\n",
      "1811/1811 [==============================] - 0s 191us/step - loss: 0.6876 - acc: 0.5494 - val_loss: 0.6989 - val_acc: 0.4570\n",
      "2264/2264 [==============================] - 0s 27us/step\n",
      "252/252 [==============================] - 0s 36us/step\n",
      "\n",
      "\n",
      "Accuracy of train:\n",
      "0.5326855123674912\n",
      "\n",
      "\n",
      "Accuracy of test:\n",
      "0.5277777763586196\n"
     ]
    }
   ],
   "source": [
    "# 讀取train.csv和test.csv\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train=train.drop([\"Unnamed: 0\"], axis=1)\n",
    "test=test.drop([\"Unnamed: 0\"], axis=1)\n",
    "\n",
    "# 將train和test的資料分為features和target\n",
    "# train_x為features,train_y為target\n",
    "# test_x為features,test_y為target\n",
    "# 將train_x和test_x做正規化\n",
    "column_list=list(train.columns.values)\n",
    "column_list.remove(\"target\")\n",
    "train_x=train[column_list]\n",
    "train_y=train[[\"target\"]]\n",
    "test_x=test[column_list]\n",
    "test_y=test[[\"target\"]]\n",
    "train_x = train_x.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "test_x = test_x.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "train_x=train_x.fillna(0)\n",
    "test_x=test_x.fillna(0)\n",
    "train_x=np.array(train_x)\n",
    "test_x=np.array(test_x)\n",
    "\n",
    "train_x= np.expand_dims(train_x, axis=1)\n",
    "test_x= np.expand_dims(test_x, axis=1)\n",
    "\n",
    "# create the model\n",
    "model=Sequential()\n",
    "\n",
    "# add layers\n",
    "model.add(LSTM(10, input_length=1, input_dim=train_x.shape[2],return_sequences=True))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid')) \n",
    "\n",
    "# show the summary\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "history=model.fit(train_x,train_y,epochs=50,batch_size=16,validation_split=0.2,verbose=1)\n",
    "\n",
    "# evaluate\n",
    "train_acc=model.evaluate(train_x,train_y)[1]\n",
    "test_acc=model.evaluate(test_x,test_y)[1]\n",
    "\n",
    "# print result\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Accuracy:\")\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
